{"cells":[{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: tensorflow in c:\\users\\91944\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.12.0)\n","Requirement already satisfied: tensorflow-intel==2.12.0 in c:\\users\\91944\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (2.12.0)\n","Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\91944\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\91944\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.6.3)\n","Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\91944\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (23.3.3)\n","Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\91944\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (0.4.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\91944\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (0.2.0)\n","Requirement already satisfied: h5py>=2.9.0 in c:\\users\\91944\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (3.8.0)\n","Requirement already satisfied: jax>=0.3.15 in c:\\users\\91944\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (0.4.7)\n","Requirement already satisfied: libclang>=13.0.0 in c:\\users\\91944\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (16.0.0)\n","Requirement already satisfied: numpy<1.24,>=1.22 in c:\\users\\91944\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.23.5)\n","Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\91944\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (3.3.0)\n","Requirement already satisfied: packaging in c:\\users\\91944\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (21.3)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\91944\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (4.22.1)\n","Requirement already satisfied: setuptools in c:\\users\\91944\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (58.1.0)\n","Requirement already satisfied: six>=1.12.0 in c:\\users\\91944\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.16.0)\n","Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\91944\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (2.2.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\91944\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (4.5.0)\n","Requirement already satisfied: wrapt<1.15,>=1.11.0 in c:\\users\\91944\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.14.1)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\91944\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.53.0)\n","Requirement already satisfied: tensorboard<2.13,>=2.12 in c:\\users\\91944\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (2.12.0)\n","Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in c:\\users\\91944\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (2.12.0)\n","Requirement already satisfied: keras<2.13,>=2.12.0 in c:\\users\\91944\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (2.12.0)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\91944\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (0.31.0)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\91944\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.12.0->tensorflow) (0.40.0)\n","Requirement already satisfied: ml-dtypes>=0.0.3 in c:\\users\\91944\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jax>=0.3.15->tensorflow-intel==2.12.0->tensorflow) (0.0.4)\n","Requirement already satisfied: scipy>=1.7 in c:\\users\\91944\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jax>=0.3.15->tensorflow-intel==2.12.0->tensorflow) (1.10.1)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\91944\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.17.0)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\91944\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (0.4.6)\n","Requirement already satisfied: markdown>=2.6.8 in c:\\users\\91944\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (3.4.3)\n","Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\91944\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.28.1)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\91944\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (0.7.0)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\91944\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (1.8.1)\n","Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\91944\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.2.3)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\91944\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from packaging->tensorflow-intel==2.12.0->tensorflow) (3.0.9)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\91944\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (5.3.0)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\91944\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (0.2.8)\n","Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\91944\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\91944\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (1.3.1)\n","Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\91944\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.1.1)\n","Requirement already satisfied: idna<4,>=2.5 in c:\\users\\91944\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (3.3)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\91944\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (1.26.12)\n","Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\91944\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2022.6.15)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\91944\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.1.1)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\91944\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (0.4.8)\n","Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\91944\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (3.2.2)\n"]},{"name":"stderr","output_type":"stream","text":["\n","[notice] A new release of pip is available: 23.1.2 -> 23.3.2\n","[notice] To update, run: python.exe -m pip install --upgrade pip\n"]}],"source":["! pip install tensorflow"]},{"cell_type":"code","execution_count":13,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2022-08-28T00:13:00.709500Z","iopub.status.busy":"2022-08-28T00:13:00.708802Z","iopub.status.idle":"2022-08-28T00:13:08.771755Z","shell.execute_reply":"2022-08-28T00:13:08.770711Z","shell.execute_reply.started":"2022-08-28T00:13:00.709398Z"},"trusted":true},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","import os\n","import tensorflow\n","from keras.utils import load_img\n","\n","# Importing Deep Learning Libraries\n","\n","# from keras.preprocessing.image import load_img, img_to_array\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.layers import Dense,Input,Dropout,GlobalAveragePooling2D,Flatten,Conv2D,BatchNormalization,Activation,MaxPooling2D\n","from keras.models import Model,Sequential\n","#from keras.optimizers\n","#import Adam,SGD,RMSprop"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2022-08-28T00:13:08.774273Z","iopub.status.busy":"2022-08-28T00:13:08.773676Z","iopub.status.idle":"2022-08-28T00:13:08.779874Z","shell.execute_reply":"2022-08-28T00:13:08.777966Z","shell.execute_reply.started":"2022-08-28T00:13:08.774242Z"},"trusted":true},"outputs":[],"source":["picture_size = 48\n","folder_path = \".\\AI_Pain_fall_Monitor\\images\"\n","# C:\\Users\\91944\\Downloads\\AI_Pain_fall_Monitor\\AI_Pain_fall_Monitor\\image.jpeg\n"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2022-08-28T00:13:08.781636Z","iopub.status.busy":"2022-08-28T00:13:08.780983Z","iopub.status.idle":"2022-08-28T00:13:10.133195Z","shell.execute_reply":"2022-08-28T00:13:10.131908Z","shell.execute_reply.started":"2022-08-28T00:13:08.781603Z"},"trusted":true},"outputs":[{"ename":"FileNotFoundError","evalue":"[WinError 3] The system cannot find the path specified: '.\\\\AI_Pain_fall_Monitor\\\\imagestrain/happy'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","Cell \u001b[1;32mIn [19], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m1\u001b[39m): \u001b[38;5;66;03m#9 images\u001b[39;00m\n\u001b[0;32m      5\u001b[0m     plt\u001b[38;5;241m.\u001b[39msubplot(\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m3\u001b[39m,i)  \u001b[38;5;66;03m#3*3 matrix size\u001b[39;00m\n\u001b[0;32m      6\u001b[0m     img \u001b[38;5;241m=\u001b[39m load_img(folder_path\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain/\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39mexpression\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39m\n\u001b[1;32m----> 7\u001b[0m                   \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfolder_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mexpression\u001b[49m\u001b[43m)\u001b[49m[i], target_size\u001b[38;5;241m=\u001b[39m(picture_size, picture_size))\n\u001b[0;32m      8\u001b[0m     plt\u001b[38;5;241m.\u001b[39mimshow(img)   \n\u001b[0;32m      9\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n","\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: '.\\\\AI_Pain_fall_Monitor\\\\imagestrain/happy'"]},{"data":{"image/png":"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","text/plain":["<Figure size 1200x1200 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["expression = 'happy'\n","plt.style.use('dark_background')\n","plt.figure(figsize= (12,12))\n","for i in range(1, 10, 1): #9 images\n","    plt.subplot(3,3,i)  #3*3 matrix size\n","    img = load_img(folder_path+\"train/\"+expression+\"/\"+\n","                  os.listdir(folder_path + \"train/\" + expression)[i], target_size=(picture_size, picture_size))\n","    plt.imshow(img)   \n","plt.show()"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2022-08-28T00:13:38.385615Z","iopub.status.busy":"2022-08-28T00:13:38.385199Z","iopub.status.idle":"2022-08-28T00:13:53.008905Z","shell.execute_reply":"2022-08-28T00:13:53.007957Z","shell.execute_reply.started":"2022-08-28T00:13:38.385584Z"},"trusted":true},"outputs":[{"ename":"FileNotFoundError","evalue":"[WinError 3] The system cannot find the path specified: '../input/face-expression-recognition-dataset/images/train'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","Cell \u001b[1;32mIn [12], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m datagen_train  \u001b[38;5;241m=\u001b[39m ImageDataGenerator()\n\u001b[0;32m      4\u001b[0m datagen_val \u001b[38;5;241m=\u001b[39m ImageDataGenerator()\n\u001b[1;32m----> 6\u001b[0m train_set \u001b[38;5;241m=\u001b[39m \u001b[43mdatagen_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflow_from_directory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfolder_path\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m                                              \u001b[49m\u001b[43mtarget_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mpicture_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43mpicture_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m                                              \u001b[49m\u001b[43mcolor_mode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrayscale\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m                                              \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m                                              \u001b[49m\u001b[43mclass_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcategorical\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m                                              \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m test_set \u001b[38;5;241m=\u001b[39m datagen_val\u001b[38;5;241m.\u001b[39mflow_from_directory(folder_path\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidation\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     15\u001b[0m                                               target_size \u001b[38;5;241m=\u001b[39m (picture_size,picture_size),\n\u001b[0;32m     16\u001b[0m                                               color_mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgrayscale\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     17\u001b[0m                                               batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m     18\u001b[0m                                               class_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     19\u001b[0m                                               shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n","File \u001b[1;32mc:\\Users\\91944\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\preprocessing\\image.py:1648\u001b[0m, in \u001b[0;36mImageDataGenerator.flow_from_directory\u001b[1;34m(self, directory, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, keep_aspect_ratio)\u001b[0m\n\u001b[0;32m   1562\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mflow_from_directory\u001b[39m(\n\u001b[0;32m   1563\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1564\u001b[0m     directory,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1578\u001b[0m     keep_aspect_ratio\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   1579\u001b[0m ):\n\u001b[0;32m   1580\u001b[0m     \u001b[38;5;124;03m\"\"\"Takes the path to a directory & generates batches of augmented data.\u001b[39;00m\n\u001b[0;32m   1581\u001b[0m \n\u001b[0;32m   1582\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1646\u001b[0m \u001b[38;5;124;03m            and `y` is a numpy array of corresponding labels.\u001b[39;00m\n\u001b[0;32m   1647\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1648\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDirectoryIterator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1649\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1650\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1651\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtarget_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1652\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolor_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolor_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1653\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeep_aspect_ratio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_aspect_ratio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1654\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclasses\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclasses\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1655\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1656\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1657\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1658\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1659\u001b[0m \u001b[43m        \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1660\u001b[0m \u001b[43m        \u001b[49m\u001b[43msave_to_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_to_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1661\u001b[0m \u001b[43m        \u001b[49m\u001b[43msave_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1662\u001b[0m \u001b[43m        \u001b[49m\u001b[43msave_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1663\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_links\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_links\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1664\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1665\u001b[0m \u001b[43m        \u001b[49m\u001b[43minterpolation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterpolation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1666\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1667\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32mc:\\Users\\91944\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\preprocessing\\image.py:563\u001b[0m, in \u001b[0;36mDirectoryIterator.__init__\u001b[1;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, keep_aspect_ratio, dtype)\u001b[0m\n\u001b[0;32m    561\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m classes:\n\u001b[0;32m    562\u001b[0m     classes \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m--> 563\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m subdir \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m)\u001b[49m):\n\u001b[0;32m    564\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(directory, subdir)):\n\u001b[0;32m    565\u001b[0m             classes\u001b[38;5;241m.\u001b[39mappend(subdir)\n","\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: '../input/face-expression-recognition-dataset/images/train'"]}],"source":["batch_size  = 128 # one iteration it should take 128\n","\n","datagen_train  = ImageDataGenerator()\n","datagen_val = ImageDataGenerator()\n","\n","train_set = datagen_train.flow_from_directory(folder_path+\"train\",\n","                                              target_size = (picture_size,picture_size),\n","                                              color_mode = \"grayscale\",\n","                                              batch_size=batch_size,\n","                                              class_mode='categorical',\n","                                              shuffle=True)\n","\n","\n","test_set = datagen_val.flow_from_directory(folder_path+\"validation\",\n","                                              target_size = (picture_size,picture_size),\n","                                              color_mode = \"grayscale\",\n","                                              batch_size=batch_size,\n","                                              class_mode='categorical',\n","                                              shuffle=False)"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2022-08-28T00:31:35.495403Z","iopub.status.busy":"2022-08-28T00:31:35.494977Z","iopub.status.idle":"2022-08-28T00:31:35.744542Z","shell.execute_reply":"2022-08-28T00:31:35.743456Z","shell.execute_reply.started":"2022-08-28T00:31:35.495350Z"},"trusted":true},"outputs":[],"source":["from keras.optimizers import adam_v2 #stack\n","from tensorflow.keras import optimizers\n","optimizers.RMSprop\n","optimizers.Adam\n","from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n","\n","no_of_classes = 7\n","\n","model = Sequential()\n","\n","#1st CNN layer\n","model.add(Conv2D(64,(3,3),padding = 'same',input_shape = (48,48,1)))\n","model.add(BatchNormalization())\n","model.add(Activation('relu'))\n","model.add(MaxPooling2D(pool_size = (2,2)))\n","model.add(Dropout(0.25))\n","\n","#2nd CNN layer\n","model.add(Conv2D(128,(5,5),padding = 'same'))\n","model.add(BatchNormalization())\n","model.add(Activation('relu'))\n","model.add(MaxPooling2D(pool_size = (2,2)))\n","model.add(Dropout (0.25))\n","\n","#3rd CNN layer\n","model.add(Conv2D(512,(3,3),padding = 'same'))\n","model.add(BatchNormalization())\n","model.add(Activation('relu'))\n","model.add(MaxPooling2D(pool_size = (2,2)))\n","model.add(Dropout (0.25))\n","\n","#4th CNN layer\n","model.add(Conv2D(512,(3,3), padding='same'))\n","model.add(BatchNormalization())\n","model.add(Activation('relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Dropout(0.25))\n","\n","model.add(Flatten())\n","\n","#Fully connected 1st layer\n","model.add(Dense(256))\n","model.add(BatchNormalization())\n","model.add(Activation('relu'))\n","model.add(Dropout(0.25))\n","\n","\n","# Fully connected layer 2nd layer\n","model.add(Dense(512))\n","model.add(BatchNormalization())\n","model.add(Activation('relu'))\n","model.add(Dropout(0.25))\n","\n","model.add(Dense(no_of_classes, activation='softmax'))\n","\n","\n","opt = optimizers.Adam(lr = 0.0001)\n","model.compile(optimizer=opt,loss='categorical_crossentropy', metrics=['accuracy'])\n","model.summary()\n","\n","\n"]},{"cell_type":"code","execution_count":26,"metadata":{"execution":{"iopub.execute_input":"2022-08-28T00:34:08.359281Z","iopub.status.busy":"2022-08-28T00:34:08.358903Z","iopub.status.idle":"2022-08-28T00:34:08.374548Z","shell.execute_reply":"2022-08-28T00:34:08.373271Z","shell.execute_reply.started":"2022-08-28T00:34:08.359250Z"},"trusted":true},"outputs":[],"source":["from tensorflow.keras import optimizers\n","optimizers.RMSprop\n","optimizers.Adam\n","from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n","\n","checkpoint = ModelCheckpoint(\"./model.h5\", monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n","\n","early_stopping = EarlyStopping(monitor='val_loss',\n","                          min_delta=0,\n","                          patience=3,\n","                          verbose=1,\n","                          restore_best_weights=True\n","                          )\n","\n","reduce_learningrate = ReduceLROnPlateau(monitor='val_loss',\n","                              factor=0.2,\n","                              patience=3,\n","                              verbose=1,\n","                              min_delta=0.0001)\n","\n","callbacks_list = [early_stopping,checkpoint,reduce_learningrate]\n","\n","epochs = 48\n","\n","model.compile(loss='categorical_crossentropy',\n","              optimizer = optimizers.Adam(lr=0.001),\n","              metrics=['accuracy'])"]},{"cell_type":"code","execution_count":27,"metadata":{"execution":{"iopub.execute_input":"2022-08-28T00:34:59.406884Z","iopub.status.busy":"2022-08-28T00:34:59.406454Z","iopub.status.idle":"2022-08-28T02:40:00.265228Z","shell.execute_reply":"2022-08-28T02:40:00.263993Z","shell.execute_reply.started":"2022-08-28T00:34:59.406851Z"},"trusted":true},"outputs":[],"source":["history = model.fit_generator(generator=train_set,\n","                                steps_per_epoch=train_set.n//train_set.batch_size,\n","                                epochs=epochs,\n","                                validation_data = test_set,\n","                                validation_steps = test_set.n//test_set.batch_size,\n","                                callbacks=callbacks_list\n","                                )"]},{"cell_type":"code","execution_count":29,"metadata":{"execution":{"iopub.execute_input":"2022-08-28T02:43:56.667858Z","iopub.status.busy":"2022-08-28T02:43:56.667289Z","iopub.status.idle":"2022-08-28T02:43:57.102636Z","shell.execute_reply":"2022-08-28T02:43:57.101377Z","shell.execute_reply.started":"2022-08-28T02:43:56.667812Z"},"trusted":true},"outputs":[],"source":["plt.style.use('dark_background')\n","\n","plt.figure(figsize=(20,10))\n","plt.subplot(1, 2, 1)\n","plt.suptitle('Optimizer : Adam', fontsize=10)\n","plt.ylabel('Loss', fontsize=16)\n","plt.plot(history.history['loss'], label='Training Loss')\n","plt.plot(history.history['val_loss'], label='Validation Loss')\n","plt.legend(loc='upper right')\n","\n","plt.subplot(1, 2, 2)\n","plt.ylabel('Accuracy', fontsize=16)\n","plt.plot(history.history['accuracy'], label='Training Accuracy')\n","plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n","plt.legend(loc='lower right')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["filename=\"model.h5\"\n","model.save()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.4"}},"nbformat":4,"nbformat_minor":4}
